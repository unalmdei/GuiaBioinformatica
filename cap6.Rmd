---
title: "cap6 Testeo - Pruebas"
date: '2022-06-17'
output:
  rmdformats::downcute:
    lightbox: true
    gallery: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 6.1 Objetivos de este Capítulo 

* Familiarizarnos con la maquinaria estadística de la prueba de hipótesis, su vocabulario, su propósito y sus fortalezas y limitaciones.

* Comprenda lo que significan las pruebas múltiples.

    Vea que las pruebas múltiples no son un problema, sino más bien una oportunidad, ya que supera muchas de las limitaciones de las pruebas individuales.

* Comprender la tasa de descubrimiento falso.

* Aprenda a hacer diagramas de diagnóstico.

* Utilice la ponderación de hipótesis para aumentar el poder de nuestros análisis.


```{r, warning=FALSE,message=FALSE}
library(pacman)
p_load("tibble","dplyr","ggplot2","gganimate","magick","transformr")
require("transformr")
```

```{r}
makedata = function(px, f1, f2, pi0, xcut, what) {
  stopifnot(length(px)==length(f1), 
            length(px)==length(f2), 
            length(pi0)==1, 
            length(xcut)==1,
            length(what)==1,
            pi0>=0, pi0<=1)
  f1 = f1 * pi0
  f2 = f2 * (1-pi0)
  i1 = which(px >= xcut)
  i2 = seq(1, i1[1], by = 1L)
  maxf1 = max(f1)
  maxf2 = max(f2)
  bind_rows(  
  tibble(
    x = px[c(i1, rev(i1))],
    y = c(f1[i1], rep(0, length(i1))),
    outcome = "True Negative"),
  tibble(
    x = px[c(i2, rev(i2))],
    y = c(f1[i2], rep(0, length(i2))),
    outcome = "False Positive"),
  tibble(
    x = px[c(i1, rev(i1))],
    y = c(f2[i1], rep(0, length(i1))) + maxf1,
    outcome = "False Negative"),
  tibble(
    x = px[c(i2, rev(i2))],
    y = c(f2[i2], rep(0, length(i2))) + maxf1,
    outcome = "True Positive"),
  tibble(
    x = rep(xcut, 3L),
    y = c(0, maxf1+maxf2, 0),
    outcome = ""
  )) |>
  bind_cols(tibble(xcut = xcut, what = what))
} 
findclosest = function(x, x0) {x[which.min(abs(x-x0))]}
pi0 = 2/3
t_df = 4
pxa = seq(-4, 4, length.out = 500)
pxb = pt(pxa, df = t_df)
xcuta = findclosest(pxa, qt(0.05, df = t_df))
xcutb = findclosest(pxb,    0.05)
f1a = dt(pxa, df = t_df) 
f2a = dgamma(pxa + 4, shape = 2, rate = 0.8) 
chainrulefac = (diff(pxa)/diff(pxb)) |> {\(x) c(x, last(x))}()
f1b = f1a * chainrulefac |> {\(x) x/sum(x)}()
f2b = f2a * chainrulefac |> {\(x) x/sum(x)}()
f1b = f1b/sum(f1b)
f2b = f2b/sum(f2b)
df = bind_rows(
  makedata(pxa, f1a, f2a, pi0, xcuta, "x"),
  makedata(pxb, f1b, f2b, pi0, xcutb, "p-value")
) 
make_static_plot = function(df) {
  stopifnot(nrow(df)>=3)
  colpal = setNames(
      c(RColorBrewer::brewer.pal(12, "Paired")[c(6,5,1,2)], "black"),
      c("True Positive", "False Negative",
        "False Positive", "True Negative", ""))
  ggplot(df, aes(x = x, y = y, fill = outcome, col = outcome)) + 
    geom_polygon() +
    scale_fill_manual(values = colpal) +
    scale_colour_manual(values = colpal) +
    xlab("value") +
    theme(legend.position = "bottom",
          legend.title = element_blank(), 
          axis.title.y = element_blank(), 
          axis.text.y  = element_blank(),
          axis.ticks.y = element_blank())
}
```


```{r}
make_static_plot(dplyr::filter(df, what == "x"))
```

```{r}
make_static_plot(dplyr::filter(df, what == "p-value"))
```

```{r}
p1 <- make_static_plot(df) + 
  labs(title = "{closest_state}") +
  transition_states(what,
                    transition_length = 3,
                    state_length = 1) + 
  view_follow() +
  ease_aes("cubic-in-out")
animate(p1, renderer = magick_renderer(), width = 5.6, height = 3, units = "in", res = 150, device = "png")
```

# 6.2 Un ejemplo: lanzamiento de una moneda 

```{r}
set.seed(0xdada)
numFlips = 100
probHead = 0.6
coinFlips = sample(c("H", "T"), size = numFlips,
  replace = TRUE, prob = c(probHead, 1 - probHead))
head(coinFlips)
```

```{r}
table(coinFlips)
```

Graficamos la Ecuación; en buena medida, también marcamos el valor observado numHeadscon una línea azul vertical. 

```{r}
library("dplyr")
k = 0:numFlips
numHeads = sum(coinFlips == "H")
binomDensity = tibble(k = k,
     p = dbinom(k, size = numFlips, prob = 0.5))
```

```{r}
library("ggplot2")
ggplot(binomDensity) +
  geom_bar(aes(x = k, y = p), stat = "identity") +
  geom_vline(xintercept = numHeads, col = "blue")
```
Todavía podemos usar la simulación de Monte Carlo para darnos algo con lo que comparar: 

```{r}
numSimulations = 10000
outcome = replicate(numSimulations, {
  coinFlips = sample(c("H", "T"), size = numFlips,
                     replace = TRUE, prob = c(0.5, 0.5))
  sum(coinFlips == "H")
})
ggplot(tibble(outcome)) + xlim(-0.5, 100.5) +
  geom_histogram(aes(x = outcome), binwidth = 1, center = 50) +
  geom_vline(xintercept = numHeads, col = "blue")
```

Como era de esperar, el número más probable de caras es 50, es decir, la mitad del número de lanzamientos de monedas. Pero vemos que otros números cercanos a 50 también son bastante probables. ¿Cómo cuantificamos si el valor observado, 59, se encuentra entre los valores que es probable que veamos en una moneda justa, o si su desviación del valor esperado ya es lo suficientemente grande como para que podamos concluir con suficiente confianza que la moneda está sesgada? ? Dividimos el conjunto de todos los k (0 a 100) en dos subconjuntos complementarios, la rechazo y la región de no rechazo.

```{r}
library("dplyr")
alpha = 0.05
binomDensity = arrange(binomDensity, p) |>
        mutate(reject = (cumsum(p) <= alpha))
ggplot(binomDensity) +
  geom_bar(aes(x = k, y = p, col = reject), stat = "identity") +
  scale_colour_manual(
    values = c(`TRUE` = "red", `FALSE` = "darkgrey")) +
  geom_vline(xintercept = numHeads, col = "blue") +
  theme(legend.position = "none")
```

Acabamos de pasar por los pasos de una prueba binomial. De hecho, esta es una actividad tan frecuente en R que se ha incluido en una sola función y podemos comparar su salida con nuestros resultados. 

```{r}
binom.test(x = numHeads, n = numFlips, p = 0.5)
```
# 6.3 Los cinco pasos de la prueba de hipótesis 

```{r}
dat <- data.frame(c('**Reject null hypothesis**', '**Do not reject**'),
                          c('Type I error (false positive)', 'True negative'),
                          c('True positive', 'Type II error (false negative)'))
            knitr::kable(dat, col.names = c('Test vs reality', 'Null hypothesis is true', '$...$ is false'), caption = 'Types of error in a statistical test.')
```

```{r}
.myttest = function(x, y) {
  mx  = mean(x)
  my  = mean(y)
  s12 = sqrt((sum((x-mx)^2)+sum((y-my)^2)) / (length(x)+length(y)-2))
  (mx - my) / s12 * sqrt(length(x)*length(y)/(length(x)+length(y)))
}
replicate(100, {
  x = rnorm(ceiling(30 * runif(1)))
  y = rnorm(ceiling(30 * runif(1)))
  stopifnot(abs(.myttest(x, y) - t.test(x, y, var.equal=TRUE)$statistic) < 1e-9)
})
```

# 6.5 La prueba t 

```{r}
p_load("ggbeeswarm")
data("PlantGrowth")
ggplot(PlantGrowth, aes(y = weight, x = group, col = group)) +
  geom_beeswarm() + theme(legend.position = "none")
tt = with(PlantGrowth,
          t.test(weight[group =="ctrl"],
                 weight[group =="trt2"],
                 var.equal = TRUE))
tt
```
Para calcular el valor p, el t.testfunción utiliza la teoría asintótica para la t -estadística; esta teoría establece que bajo la hipótesis nula de igualdad de medias en ambos grupos, el estadístico sigue una distribución matemática conocida, la denominada t -distribución con n 1 + n 2 grados de libertad. 

```{r}
abs_t_null = with(
  dplyr::filter(PlantGrowth, group %in% c("ctrl", "trt2")),
    replicate(10000,
      abs(t.test(weight ~ sample(group))$statistic)))
ggplot(tibble(`|t|` = abs_t_null), aes(x = `|t|`)) +
  geom_histogram(binwidth = 0.1, boundary = 0) +
  geom_vline(xintercept = abs(tt$statistic), col = "red")
mean(abs(tt$statistic) <= abs_t_null)
```


```{r}
with(rbind(PlantGrowth, PlantGrowth),
       t.test(weight[group == "ctrl"],
              weight[group == "trt2"],
              var.equal = TRUE))
```

# 6.6 Hackeo del valor P 

# 6.7 Pruebas múltiples 
```{r}
dat <- data.frame(c('**Rejected**', '**Not rejected**', '**Total**'),
                              c('$V$', '$U$', '$m_0$'),
                              c('$S$', '$T$','$m-m_0$'),
                              c('$R$', '$m-R$', '$m$'))
            knitr::kable(dat, col.names = c('Test vs reality', 'Null hypothesis is true', '$...$ is false', 'Total'), caption = 'Types of error in multiple testing. The letters designate the number of
    times each type of error occurs.')
```

# 6.8 La tasa de error inteligente de la familia 

```{r}
1 - (1 - 1/1e6)^8e5
```

## 6.8.1 Corrección de Bonferroni 

Corrección de Bonferroni. La gráfica muestra para m = 10 4 en función de α . 

```{r}
m = 10000
ggplot(tibble(
  alpha = seq(0, 7e-6, length.out = 100),
  p     = 1 - (1 - alpha)^m),
  aes(x = alpha, y = p)) +  geom_line() +
  xlab(expression(alpha)) +
  ylab("Prob( no false rejection )") +
  geom_hline(yintercept = 0.05, col = "red")
```

# 6.9 La tasa de descubrimiento falso

```{r, warning=FALSE,message=FALSE}
p_load("DESeq2","airway")
data("airway")
aw   = DESeqDataSet(se = airway, design = ~ cell + dex)
aw   = DESeq(aw)
awde = as.data.frame(results(aw)) |> dplyr::filter(!is.na(pvalue))
```


## 6.9.1 El histograma del valor p 

```{r}
ggplot(awde, aes(x = pvalue)) +
  geom_histogram(binwidth = 0.025, boundary = 0)
```

Estimación visual de la FDR con el histograma de valor p. 

```{r}
alpha = binw = 0.025
pi0 = 2 * mean(awde$pvalue > 0.5)
ggplot(awde,
  aes(x = pvalue)) + geom_histogram(binwidth = binw, boundary = 0) +
  geom_hline(yintercept = pi0 * binw * nrow(awde), col = "blue") +
  geom_vline(xintercept = alpha, col = "red")
```

emos que hay 4772 valores p en el primer contenedor.

```{r}
pi0 * alpha / mean(awde$pvalue <= alpha)
```

## 6.9.2 El algoritmo de Benjamini-Hochberg para controlar el FDR 

```{r}
phi  = 0.10
awde = mutate(awde, rank = rank(pvalue))
m    = nrow(awde)
ggplot(dplyr::filter(awde, rank <= 7000), aes(x = rank, y = pvalue)) +
  geom_line() + geom_abline(slope = phi / m, col = "red")
```


```{r}
kmax = with(arrange(awde, rank),
         last(which(pvalue <= phi * rank / m)))
kmax
```

El método encuentra el punto más a la derecha donde las líneas negra (nuestros valores p).

# 6.10 El FDR local 

```{r}
awdef = awde %>%
  dplyr::filter(baseMean >=1) %>% 
  arrange(pvalue) %>%
  mutate(oneminusp = 1 - pvalue,
         N = n() - row_number())
jj = round(nrow(awdef) * c(1, 0.5))
slope = with(awdef, diff(N[jj]) / diff(oneminusp[jj]))
ggplot(awdef) +
  geom_point(aes(x = oneminusp, y = N), size = 0.15) + 
  xlab(expression(1-p[i])) +
  ylab(expression(N(p[i]))) +
  geom_abline(intercept = 0, slope = slope, col = "red3") +
  geom_hline(yintercept = slope, linetype = "dotted") +
  geom_vline(xintercept = 1, linetype = "dotted") +
  geom_text(x = 0, y = slope, label = paste(round(slope)), 
            hjust = -0.1, vjust = -0.25) 
```

```{r}
pi0 = 0.6
f1 = function(t, shape2 = 7) {
   rv = dbeta(t, 1, shape2)
   rv / sum(rv) * (length(rv)-1) * (1-pi0)
}
t = seq(0, 1, length.out = 101)
t0 = 0.1
f0  = rep(pi0, length(t))
f   = f0 + f1(t)
F0  = cumsum(f0) / (length(t)-1)
F   = cumsum(f)  / (length(t)-1)
stopifnot(abs(F[length(F)] - 1) < 1e-2)
myplot = function(y, y0, ylim, yat, havepi0, colo = RColorBrewer::brewer.pal(12, "Paired")) {
  plot(x = t, y = y, type = "l", xlim = c(0, 1), ylim = ylim,
    xaxs = "i", yaxs = "i", ylab = "", yaxt = "n", xaxt = "n", xlab = "", main = deparse(substitute(y)))
  axis(side = 1, at = c(0, 1))
  axis(side = 2, at = yat)
  xa  =  t[t<=t0]
  xb  =  t[t>=t0]
  y0a = y0[t<=t0]
  y0b = y0[t>=t0]
  ya  =  y[t<=t0]
  polygon(x = c(xa, rev(xa)), y = c(y[t<=t0], rev(y0a)), col = colo[2])
  polygon(x = c(xb, rev(xb)), y = c(y[t>=t0], rev(y0b)), col = colo[1])
  polygon(x = c(xa, rev(xa)), y = c(rep(0, length(xa)), rev(y0a)), col = "#c0c0c0")
  polygon(x = c(xb, rev(xb)), y = c(rep(0, length(xb)), rev(y0b)), col = "#f0f0f0")
  segments(x0 = rep(t0, 2), x1 = rep(t0, 2), y0 = c(0, last(y0a)), y1 = c(last(y0a), last(ya)),
           col = colo[5:6], lwd = 3)
  text(t0, 0, adj = c(0, 1.8), labels = expression(p), cex = 1, xpd = NA)
  if (havepi0)
      text(0, pi0, adj = c(1.5, 0.5), labels = expression(pi[0]), cex = 1, xpd = NA)
}
par(mai = c(1, 0.6, 0.4, 0.3), mfcol = c(2,1))
myplot(f, f0, ylim = c(0, f[1]), yat = c(0:3),       havepi0 = TRUE)
myplot(F, F0, ylim = c(0, 1),    yat = c(0, 0.5, 1), havepi0 = FALSE)
```

Los paquetes qvalue y fdrtool ofrecen facilidades para ajustar estos modelos a los datos. 

```{r}
p_load("fdrtool")
ft = fdrtool(awde$pvalue, statistic = "pvalue")
```

```{r}
ft$param[,"eta0"]
```

# 6.11 Filtrado independiente y ponderación de hipótesis

```{r}
awde$baseMean[1]
cts = counts(aw, normalized = TRUE)[1, ]
cts
mean(cts)
```

```{r}
stopifnot(abs(mean(cts)-awde$baseMean[1])<1e-9)
```

```{r}
ggplot(awde, aes(x = asinh(baseMean))) +
  geom_histogram(bins = 60)
```

```{r}
ggplot(awde, aes(x = rank(baseMean), y = -log10(pvalue))) +
  geom_hex(bins = 60) +
  theme(legend.position = "none")
```

### Pregunta 

En el diagrama de dispersión, ¿por qué usamos − log 10 para los valores de p? ¿Por qué la transformación de rango para el baseMean? 

```{r}
awde = mutate(awde, stratum = cut(baseMean, include.lowest = TRUE,
  breaks = signif(quantile(baseMean,probs=seq(0,1,length.out=7)),2)))
```

```{r}
ggplot(awde, aes(x = pvalue)) + facet_wrap( ~ stratum, nrow = 4) +
  geom_histogram(binwidth = 0.025, boundary = 0)
```

```{r}
ggplot(awde, aes(x = pvalue, col = stratum)) +
  stat_ecdf(geom = "step") + theme(legend.position = "bottom")
```

¿Podemos usar eso para una mejor corrección de pruebas múltiples? Resulta que esto es posible. Podemos utilizar filtrado independiente  (Bourgon, Gentleman y Huber 2010 ) o ponderación de hipótesis independiente (IHW) (Ignatiadis et al. 2016 ). 

```{r, message=FALSE, warning=FALSE}
library(pacman)
p_load("IHW")
ihw_res = ihw(awde$pvalue, awde$baseMean, alpha = 0.1)
rejections(ihw_res)
```

Comparemos esto con lo que obtenemos del método ordinario (no ponderado) de Benjamini-Hochberg: 

```{r}
padj_BH = p.adjust(awde$pvalue, method = "BH")
sum(padj_BH < 0.1)
```

Pesos de hipótesis determinados por el ihwfunción. Aquí, la configuración predeterminada de la función eligió 22 estratos, mientras que en nuestra exploración manual anterior.

```{r}
plot(ihw_res)
```
